{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: Demonstrate how to load a dataset suitable for recommendation systems into a PySpark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lplab/anaconda3/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-----+\n",
      "|       user_id|product_id|score|\n",
      "+--------------+----------+-----+\n",
      "|A141HP4LYPWMSR|B003AI2VGA|  3.0|\n",
      "|A328S9RN3U5M68|B003AI2VGA|  3.0|\n",
      "|A1I7QGUDP043DG|B003AI2VGA|  5.0|\n",
      "|A1M5405JH9THP9|B003AI2VGA|  3.0|\n",
      "| ATXL536YX71TR|B003AI2VGA|  3.0|\n",
      "+--------------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "import findspark\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "ratings = spark.read.json(\"movies 1.json\").select(\"user_id\",\"product_id\",\"score\").cache()\n",
    "ratings = ratings.head(10000)\n",
    "ratings = spark.createDataFrame(ratings)\n",
    "\n",
    "ratings.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: Implement a PySpark script that splits the data and trains a recommendation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-----+-------------+----------------+-----------+\n",
      "|user_id       |product_id|score|user_id_index|product_id_index|prediction |\n",
      "+--------------+----------+-----+-------------+----------------+-----------+\n",
      "|A3MV1KKHX51FYT|B008FPU7AA|3.0  |85.0         |112.0           |0.17213519 |\n",
      "|ADX5JX5LKLC22 |B000063W1R|5.0  |580.0        |7.0             |4.9947615  |\n",
      "|A3ENN12GLNTUAF|B0071AD95K|5.0  |493.0        |128.0           |-1.9853785 |\n",
      "|A2NUHWMHA9XNKV|B000063W1R|5.0  |157.0        |7.0             |-3.2191253 |\n",
      "|A3N2MVBI1A2I9Y|B000063W1R|5.0  |519.0        |7.0             |-0.7700126 |\n",
      "|A28ILXH590CMRJ|B000063W1R|4.0  |355.0        |7.0             |1.1505669  |\n",
      "|A13TO1ZFAH9SVN|B000063W1R|5.0  |235.0        |7.0             |-2.1389847 |\n",
      "|A1TK6WNUIAEQRU|B000NDFLWG|4.0  |326.0        |91.0            |-0.26183853|\n",
      "|A2NJO6YE954DBH|B000063W1R|4.0  |8.0          |7.0             |-3.544883  |\n",
      "|A41I67QYRAOSQ |B000063W1R|4.0  |550.0        |7.0             |-0.7700126 |\n",
      "+--------------+----------+-----+-------------+----------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(ratings)\n",
    "    for column in [\"user_id\", \"product_id\"]\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "ratings_indexed = pipeline.fit(ratings).transform(ratings)\n",
    "\n",
    "training_data,validation_data = ratings_indexed.randomSplit([8.0,2.0])\n",
    "\n",
    "als = ALS(userCol=\"user_id_index\",itemCol=\"product_id_index\",ratingCol=\"score\",rank=10,maxIter=5,regParam=0.01,coldStartStrategy=\"drop\")\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\",labelCol=\"score\",predictionCol=\"prediction\")\n",
    "\n",
    "model = als.fit(training_data)\n",
    "predictions=model.transform(validation_data)\n",
    "predictions.show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3: Implement a PySpark script using the ALS algorithm for collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-------------+----------------+\n",
      "|product_id|      user_id|user_id_index|product_id_index|\n",
      "+----------+-------------+-------------+----------------+\n",
      "|0800103688|ANCOMAI0I7LVG|          1.0|            30.0|\n",
      "|B004EPYZQ2|ANCOMAI0I7LVG|          1.0|             3.0|\n",
      "|B0001EYSQC|ANCOMAI0I7LVG|          1.0|            31.0|\n",
      "+----------+-------------+-------------+----------------+\n",
      "\n",
      "+----------+-------------+-------------+----------------+----------+\n",
      "|product_id|      user_id|user_id_index|product_id_index|prediction|\n",
      "+----------+-------------+-------------+----------------+----------+\n",
      "|B0001EYSQC|ANCOMAI0I7LVG|          1.0|            31.0|-0.8538896|\n",
      "|B004EPYZQ2|ANCOMAI0I7LVG|          1.0|             3.0|-3.5181665|\n",
      "|0800103688|ANCOMAI0I7LVG|          1.0|            30.0|-13.863456|\n",
      "+----------+-------------+-------------+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user1 = validation_data.filter(validation_data['user_id_index']==1.0).select(['product_id','user_id','user_id_index','product_id_index'])\n",
    "user1.show()\n",
    "recommendations = model.transform(user1) \n",
    "recommendations.orderBy('prediction',ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4: Implement code to evaluate the performance of the recommendation model using appropriate metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) = 5.40235713605181\n",
      "Mean Absolute Error (MAE) = 4.209195835054521\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) = {rmse}\")\n",
    "\n",
    "# Additional Evaluation Metric: Mean Absolute Error (MAE)\n",
    "evaluator_mae = RegressionEvaluator(\n",
    "    metricName=\"mae\",\n",
    "    labelCol=\"score\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "mae = evaluator_mae.evaluate(predictions)\n",
    "print(f\"Mean Absolute Error (MAE) = {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
